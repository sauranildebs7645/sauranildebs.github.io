<div class="row">
    <h2>Projects</h2>
    <hr>


<table width="100%" align="left" border="0" cellspacing="0" cellpadding="20" style="border-collapse:separate; border-spacing:25px;">
	<tbody style="text-align:left;">

        
    <tr>
		<td valign="top" width="30%">
			 <img src="/static/img/spectro.png" width="250" height="auto">
		</td>
		<td valign="top" height = "80%" width="80%">
			<b>Low cost, Portable LED-Spectrophotometer for the Detection of Nitrite in Urine</b>
      <br> (Accepted at IEEE UPCON 2019) <br> 
			<b>Sauranil Debarshi,</b>
			<a href="https://scholar.google.co.in/citations?user=YEbRuroAAAAJ&hl=en">Mohd Mansoor Khan</a>

		</td>
	</tr>
	

    <tr>
		<td valign="top" width="30%">
	    <img src="/static/img/HINT_teaser.png" width="250" height="auto">
		</td>
		<td valign="top" width="70%">
			<b>Taking a HINT: Levaraging Explanations to Make Vision and Language Models More Grounded</b>
      <br> (Preliminarly version presented in Debug-ML workshop at ICLR'19) <br> 
      <b href="http://ramprs.github.io">Ramprasaath R. Selvaraju</b>,
			<a href="https://www.cc.gatech.edu/~slee3191/">Stefen Lee</a>,
			<a href="">Yilin Shen</a>, 
			<a href="">Hongxia Jin</a>,
			<a href="">Shalini Ghosh</a>,
			<a href="https://www.cc.gatech.edu/~dbatra/">Dhruv Batra</a>, 
			<a href="https://www.cc.gatech.edu/~parikh/">Devi Parikh</a>
			<br>
			<a href="https://arxiv.org/abs/1902.03751">Arxiv Paper: https://arxiv.org/abs/1902.03751</a> 
			<br>
			<br>
		</td>
	</tr>
	

    <tr>
		<td valign="top" width="30%">
			 <img src="/static/img/NIWT_teaser.png" width="250" height="auto">
		</td>
		<td valign="top" width="70%">
			<b>Choose Your Neuron: Incorporating Domain Knowledge into Deep Networks through Neuron Importance</b>
      <br> (Presented in ECCV'18) <br> 
      <b href="http://ramprs.github.io">Ramprasaath R. Selvaraju*</b>,
			<a href="https://about.me/chattopadhyayprithvijit">Prithviraj Chattopadhyay*</a>, 
			<a href="https://sites.google.com/site/mhelhoseiny/">Mohamed Elhoseiny</a>,
			<a href="">Tilak Sharma</a>,
			<a href="https://www.cc.gatech.edu/~dbatra/">Dhruv Batra</a>,
			<a href="https://www.cc.gatech.edu/~parikh/">Devi Parikh</a>,
			<a href="https://www.cc.gatech.edu/~slee3191/">Stefen Lee</a>,
			<br>
			<a href="https://arxiv.org/abs/1808.02861">Arxiv Paper: https://arxiv.org/abs/1808.02861</a> 
			<br>
			<br>
		</td>
	</tr>
	

	<tr>
		<td valign="top" width="30%">
			 <img src="/static/img/Grad-CAM_teaser.png" width="250" height="auto">
		</td>
		<td valign="top" width="70%">
			<b>Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</b>
      <br> (Presented in ICCV'17 and accepted to IJCV) <br> 
      <b href="http://ramprs.github.io">Ramprasaath R. Selvaraju</b>,
			<a href="mcogswell.io">Michael Cogswell</a>,  
      <a href="http://abhishekdas.com/about/">Abhishek Das</a>, 
			<a href="http://ramakrishnavedantam928.github.io/">Ramakrishna Vedantam</a>, 
			<a href="https://www.cc.gatech.edu/~parikh/">Devi Parikh</a>,
			<a href="https://www.cc.gatech.edu/~dbatra/">Dhruv Batra</a>,
			<br>
			<a href="https://arxiv.org/abs/1610.02391">Arxiv Paper: https://arxiv.org/abs/1610.02391</a> 
			[<a href="https://github.com/ramprs/grad-cam/">Code</a>]
			[<a href="http://gradcam.cloudcv.org/">Live Demo</a>]
			<br>
			<br>
		</td>
	</tr>
	
	<tr>
		<td valign="top" width="30%">
			 <img src="/static/img/dbs_teaser.png" width="250" height="auto">
		</td>
		<td valign="top" width="70%">
			<b>Diverse Beam Search: Diverse Decoding from Neural Sequence Models</b>
      <br> (Presented in AAAI'18) <br> 
			<br> 
			<a href="https://computing.ece.vt.edu/~ashwinkv/">Ashwin Kalyan</a>, 
			<a href="mcogswell.io">Michael Cogswell</a>, 
      <b href="http://ramprs.github.io">Ramprasaath R. Selvaraju</b>,
			<a href="https://computing.ece.vt.edu/~sunqing/">Qing Sun</a>,
			<a href="https://www.cc.gatech.edu/~slee3191/">Stefen Lee</a>,
			<a href="https://www.cs.indiana.edu/~djcran/">David Crandal</a>,
			<a href="https://www.cc.gatech.edu/~dbatra/">Dhruv Batra</a>
            <br>
			<a href="https://arxiv.org/abs/1610.02424">Arxiv Paper: https://arxiv.org/abs/1610.02424</a> 
            <br>
			[<a href="https://github.com/ashwinkalyan/dbs">Code</a>]
    		<br>
			<br>
			</td>
	</tr>
	<tr>
		<td valign="top" width="30%">
			 <img src="/static/img/counting_teaser.PNG" width="250" height="auto">
		</td>
		<td valign="top" width="70%">
			<b>Counting Everyday Objects in Everyday Scenes</b>
			<br> (Spotlight talk at CVPR'17) <br> 
			<a href="https://about.me/chattopadhyayprithvijit">Prithviraj Chattopadhyay*</a>, 
			<a href="http://vrama91.github.io/">Ramakrishna Vedantam*</a>,
            <b href="http://ramprs.github.io">Ramprasaath R. Selvaraju</b>,
			<a href="https://www.cc.gatech.edu/~dbatra/">Dhruv Batra</a>, 
			<a href="https://www.cc.gatech.edu/~parikh/">Devi Parikh</a>
			<br>
			[<a href= "https://arxiv.org/abs/1604.03505"> ArXiv paper: https://arxiv.org/abs/1604.03505</a>] 
			<br>
			<br>
		</td>
	</tr>

<tr>
		<td valign="top" width="30%">
			 <img src="/static/img/paintbrush_teaser.jpg" width="250" height="auto">
		</td>
		<td valign="top" width="70%">
			<b>The Semantic Paintbrush: Interactive 3D Mapping and Recognition in Large Outdoor Spaces</b>
			<br> (Oral at CHI'15) <br> 
			<a href="http://www.miksik.co.uk/">Ondrej Miksik</a>,
			<a href="http://stanford.edu/~vibhavv/index.html">Vibhav Vineet</a>,
			<a href="http://morten.lidegaard.net/">Morten Lidegaard</a>,
            <b href="http://ramprs.github.io">Ramprasaath R. Selvaraju</b>,
			<a href="http://graphics.stanford.edu/~niessner/publications.html">Matthias Nießner</a>,
			<a href="http://www.cs.ox.ac.uk/people/stuart.golodetz/">Stuart Golodetz</a>,
			<a href="http://www.ndcn.ox.ac.uk/departments/DCN/team/research-scientists/stephen-hicks">Stephen L. Hicks</a>,
			<a href="http://www.technicolor.com/en/patrick-perez">Patrick Pérez</a>,
			<a href="http://research.microsoft.com/en-us/people/shahrami/">Shahram Izadi</a>,
			<a href="http://www.robots.ox.ac.uk/~tvg/people.php">Philip H. S. Torr</a>
			[<a href= "http://www.graphics.stanford.edu/~niessner/papers/2015/2paintbrush/miksik2015chi.pdf"> Paper</a>] 
			<br>
		</td>
	</tr>


	<tr>
		<td valign="top" width="30%">
			 <img src="/static/img/blindfold.png" width="250" height="auto">
		</td>
		<td valign="top" width="70%">
			<b>BlindFind: Wearable Computer-Vision Rig for the Visually Impaired</b>
			<br> 
			<a href="">Eduardo Schmidt</a>,
            <a href="https://ramprs.github.io"><b>Ramprasaath R Selvaraju</b></a>,
			<a href="">Joshua</a>,
			<a href="">Brandon</a>,
			<a href="">Krishna</a>,
			<a href="">Brian</a>,
			<a href="">Fırat Kalaycılar</a>,
			<a href="https://vivo.brown.edu/display/bkimia">Benjamin Kimia</a>
		</td>
	</tr>

</tbody></table>

<!--
    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading"><a target="_blank" href="http://gradcam.cloudcv.org">Gradient-weighted Class Activation Mapping (Grad-CAM)</a> Demo</h3>
        <br>
        <p>Gradient-weighted Class Activation Mapping (Grad-CAM) is a novel class-discriminative localization technique, that can be used to make CNN based models interpretable. Grad-CAM highlights regions of the image the VQA model looks at while making predictions. Given an image and a caption or question about that image, the model shows where it looked while doing prediction.</p>
        <a class="github-button btn" href="https://github.com/cloud-cv/grad-cam" data-size="large" data-show-count="false" aria-label="cloud-cv/grad-cam on GitHub">Code</a>
        <a class="github-button" href="https://github.com/cloud-cv/grad-cam" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star cloud-cv/grad-cam on GitHub">Star</a>
        <a class="github-button" href="https://github.com/cloud-cv/grad-cam/fork" data-icon="octicon-repo-forked" data-size="large" data-show-count="true" aria-label="Fork cloud-cv/grad-cam on GitHub">Fork</a>
      </div>
    </div>
    <br>
    <div class="row" align="center">
      <div class="col-sm-6">
        <h4><a href="http://gradcam.cloudcv.org/vqa">Grad-CAM VQA Demo</a></h4>
        <a href="http://gradcam.cloudcv.org/vqa"><img src="/static/img/gcam_vqa.gif" width="100%"></a>
      </div>
      <div class="col-sm-6">
        <h4><a href="http://gradcam.cloudcv.org/classification">Grad-CAM Classification Demo</a></h4>
        <a href="http://gradcam.cloudcv.org/classification"><img src="/static/img/gcam_classification.gif" width="100%"></a>
      </div>
      <div class="col-sm-6">
        <h4><a href="http://gradcam.cloudcv.org/captioning">Grad-CAM Captioning Demo</a></h4>
        <a href="http://gradcam.cloudcv.org/captioning"><img src="/static/img/gcam_captioning.gif" width="100%"></a>
      </div>
      <div class="col-sm-6">
        <h4>Grad-CAM Demo Video</h4>
        <iframe width="100%" height="315" src="https://www.youtube.com/embed/COjUB9Izk6E?start=29" frameborder="0" allowfullscreen></iframe>
      </div>
    </div>

    <hr>
-->


</div>
