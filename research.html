---
layout: null
section-type: research
title: Research
---
## My Research



#### My research interests lie at the intersection of Computer Vision and Machine Learning, with a focus    on building algorithms that can

<ul>
    <li> explain why they believe what they believe </li>
    <li> truly understand and grasp information from different modalities (vision, language, common sense  reasoning) and create other possible scenarios </li>
</ul>

### Projects

<ul>
    <li> Making Deep Models Interpretable Without Making Interpretable Deep Models </li>
    <p> Deep CNNs have enabled significant breakthroughs for vision, but at the same time they raise       important questions about interpretability. To make these models more interpretable we start by (1) proposing a novel  class localization method called Gradient-weighted Class Activation Maps (Grad-CAM) which uses gradients to perform    localization. (2) Then we combine Grad-CAM with visualizations like Guided Backpropagation to create a novel           visualization method called Guided
    Grad-CAM. The resulting visualizations provide intuitive explanations for CNN predictions by showing   both what salient features a CNN looks at as well as where it looks. (3) Further, we empirically demonstrate that our  visualization technique is highly class-discriminative through human studies. (4) Finally, we show the broad           applicability of this visualization technique for not just image classification, but also visual question answering    and image captioning, showing how
    to interpret typically uninterpretable deep models. </p>
    <p> Arxiv link and Code coming out soon </p>

    <li> Counting Everyday Objects in Everyday Scenes </li>

    <p> We introduce the problem of counting everyday objects in everyday scenes. While previous works     have studied specific counting problems such as pedestrian counting in surveillance videos, or biological cell         counting, we are interested in counting common objects in natural scenes. We study this problem in a setup similar to  traditional scene understanding problems. Given an image, we consider the task of predicting the counts (or the        numerosity) of categories of interest. We study some simple approaches and applications for this counting problem.     Our detect approach adapts an object detector to perform counting, while our glance approach regresses to ground       truth counts. Our associative subitizing (aso-sub) approach divides an image into regions and regresses to fractional  object counts in each region. We create an ensemble (ens) of these counting methods which improves performance. We     demonstrate
    counting performance on the PASCAL and MS COCO datasets. We show proof-of-concept applications of our  automatic counting methods to 1) improve object detection performance, and 2) visual question answering (on VQA and    COCO-QA). </p>
    <p> Arxiv: </p>
    <p> Code: </p>

    <li>

</ul>

